---

title: State of OpenTelemetry in 2025 - The good, bad, and ugly
slug: state-of-otel-2025
date: 2025-08-28
tags: [OpenTelemetry]
authors: [elizabeth_mathew]
description: OpenTelemetry is the de facto standard for observability data in cloud-native systems. It's now the second-largest CNCF project after Kubernetes. This blog provides a candid and opinionated assessment of OpenTelemetry's current state in 2025, including significant new developments, ongoing challenges, and why it's worth paying attention to.
image: /img/blog/2025/08/state-of-otel.webp
keywords: [OpenTelemetry, OTel, observability, telemetry, metrics, traces, logs, instrumentation, API, SDK, collector, OTLP]

---

OpenTelemetry [OTel] has rapidly become the de facto standard for observability data in cloud-native systems. It’s now the **second-largest CNCF project after Kubernetes**, reflecting widespread industry adoption. By late 2023, OpenTelemetry had finally stabilised all three core telemetry signals: **traces, metrics, and logs,**  completing the observability *trifecta*. With logging reaching general availability, the community in 2025 has shifted focus to new frontiers beyond the original trio.

This blog provides a candid and opinionated assessment of OpenTelemetry's current state in 2025, including significant new developments, ongoing challenges, and why *it’s worth paying attention* to.

## Continuous Profiling

One of the most exciting advances is **profiling** as a first-class telemetry signal. OTel’s 2025 roadmap includes making the profiling API generally available, enabling developers to capture CPU and memory profiles natively through OTel. In practical terms, this means you can record performance profiles [e.g. CPU usage, heap allocations] alongside your traces, all within the same standardised framework. 

Even more impressive, a continuous profiling agent based on eBPF [Extended BPF] has been **donated to the OpenTelemetry project**, and its first experimental releases are expected in 2025. eBPF enables profiling at the kernel level with minimal overhead, allowing teams to continuously profile applications in production with significantly less performance impact than traditional profilers. By integrating profiling data into OpenTelemetry, engineers will be able to correlate trace spans with CPU hotspots or memory leaks, painting a richer picture of system performance. It’s a big step toward making OpenTelemetry a one-stop shop for all telemetry signals.

## Observability for AI and Machine Learning

Beyond traditional applications, OTel is expanding into **AI and ML observability** in 2025. The community is actively working on semantic conventions tailored to **Generative AI** workloads and has already released initial instrumentation for the OpenAI Python client. 

This means if your application calls an LLM or other AI service, OTel can capture details like model name, parameters [e.g. prompt, temperature], token usage, and latency as spans or metrics. Given the explosive growth of AI APIs [and their high costs], such telemetry is crucial for monitoring prompt performance, detecting anomalies, and optimising usage.

Otel’s push into AI goes beyond just generative text models. In the MLOps domain, you can now instrument model training jobs and inference pipelines using OpenTelemetry [OTel]. In fact, popular ML frameworks and platforms, such as **KServe, Kubeflow, and Flyte, have added OpenTelemetry hooks** to emit spans during model training, deployment, and inference. Telemetry from these pipelines can include GPU utilisation, model version, data loading times, and more.
The goal is to make AI/ML systems as transparent and monitorable as any microservice, using the same OpenTelemetry tooling. It’s still early days, but 2025 is seeing the first fruits of AI-focused OTel instrumentation, and we can expect emerging conventions [for example, standard attributes for model metrics] to solidify as this area matures.

## Collector Maturity and eBPF Instrumentation

Anyone who has tried deploying OTel at scale knows the **OTel Collector** is a linchpin component. The Collector is a service that receives telemetry data, processes it [batching, filtering, enriching], and exports it to your chosen backend. In 2025, the OpenTelemetry Collector is finally reaching a major milestone: **version 1.0**. This long-awaited v1.0 release marks the Collector as stable, enterprise-ready, and here to stay. A stable Collector vastly simplifies production deployments, since it can handle the heavy lifting of ingesting data from many sources and reliably routing it to one or multiple observability backends. Reaching 1.0 also means backward compatibility guarantees, which is a green light for large organizations to adopt the Collector without fear of breaking changes.

Another significant trend is the deeper integration of **eBPF for low-overhead instrumentation**. We already mentioned eBPF in the context of profiling, but it’s also being applied more broadly. In Kubernetes environments, OpenTelemetry can now leverage eBPF to automatically capture system calls, network requests, and other kernel-level events from applications with **minimal performance impact**.  This is essentially *auto-instrumentation* in the kernel, which is powerful for languages or scenarios where normal SDK instrumentation isn’t possible. By using eBPF, OpenTelemetry can gather data that would be hard to get otherwise [like network latency at the socket level, or file system access patterns] and do so cheaply. Combined with the Collector’s pipeline, this data can be filtered or sampled smartly to avoid overwhelming your backend. The bottom line is that OTel is not just a set of APIs anymore; it’s evolving into an observability *platform* that can tap into telemetry from the application layer down to the operating system, all in a standard format.

## Full-Stack Coverage: From Browser to WASM

OTel’s initial focus was on backend services. Still, in 2025, there’s a concerted effort to achieve **full-stack observability,** tracing user interactions from the frontend all the way to backend and infrastructure. On the frontend, OTel’s JavaScript and browser SDKs for Real User Monitoring (RUM) are being enhanced to make client-side tracing easier and more feature-rich. This means better support for capturing user events, page load timings, and propagating context from the browser to the server. The roadmap explicitly calls out **browser SDK improvements for full-stack tracing**, enabling a user to click a button in a web app and have their action linked to downstream API calls and database queries in a single trace. While some early versions of these libraries exist, by 2025, we expect more stable and integrated solutions [possibly even an official OpenTelemetry RUM offering] to simplify end-to-end instrumentation. This is crucial because observability gaps often exist at the client layer – if OTel can fill those, it truly earns the open telemetry *everything* moniker.

Another frontier is WebAssembly. With the rise of WASM for running code in the browser, at the edge, or even in server applications, the need for observability in WASM environments is growing. The OpenTelemetry 2025 roadmap includes **WASM instrumentation support**, aiming to allow tracing inside WebAssembly modules. Instrumenting WASM is non-trivial [since it’s a sandboxed, low-level environment]. Still, the community recognises that as more logic moves to WASM [for example, WebAssembly micro-services or plugins], observability can’t be an afterthought. By standardising a way to emit traces or metrics from WASM code, OpenTelemetry will enable developers to treat WASM modules as just another part of their distributed system – observable in the same way as any other service. These full-stack and frontier efforts [browser and WASM] ensure that OpenTelemetry remains relevant as application architectures evolve on the client side and beyond the typical server processes.

## The Hard Truths: Challenges that Remain

It’s not all smooth sailing with OpenTelemetry in 2025. As candid observers, we must acknowledge that **adopting OTel still presents challenges**. 

### Learning Curve

First, the **learning curve** is undeniably steep. Getting started requires understanding a slew of new concepts [traces, spans, metrics, semantic conventions, context propagation, etc.] and instrumentation patterns across different languages. Implementing OTel across a complex system requires deep knowledge and has a high entry point effort, as one early adopter put it. In other words, you can’t just flip a switch; teams need to invest time in learning and planning their instrumentation strategy.

### Architectural Complexity

There is also **architectural complexity** to consider. OpenTelemetry often introduces additional moving parts into your stack. Aside from instrumenting your application code or deploying auto-instrumentation agents, you will likely run one or more Collector services to buffer and route data. At scale, managing fleets of Collectors and ensuring they’re healthy becomes its own operational task. Some experts warn that as OpenTelemetry’s scope grows, it *will become more complex and challenging to configure and manage at scale*. This is a natural trade-off. OTel’s flexibility and power [supporting many signals and exporters] means there’s a lot to configure and tune. Without careful design, one can end up with an observability pipeline that is also difficult to observe.

### Documentation and support

**Documentation and support** remain a mixed bag. The project has enhanced its official documentation, and a growing collection of blog posts and examples is available. However, due to the rapid pace of development, there are still gaps and outdated information available. As Austin Parker noted, OTel can be challenging for newcomers to learn because **documentation gaps still exist** as the project evolves. Specific language SDKs or advanced features might not have the polished guides you’d expect, which can frustrate new users. Additionally, since OTel is an open-source, community-driven project, you don’t have a dedicated vendor support line to call [though many vendors offer their own distribution and support for OTel]. In practice, you rely on community forums, GitHub, and CNCF Slack channels for help, which is a wonderful community, but requires a do-it-yourself mindset at times.

Finally, while core features are stable, not everything in OpenTelemetry is fully **standardised for all edge cases**. Some newer signals [like profiling, or events] are still experimental. Semantic conventions cover common scenarios [HTTP, databases, messaging, etc.], but if your use case is unusual, you may have to define custom attributes or await future spec enhancements. For example, **Real User Monitoring** was not stable for a long time; it’s improving, but front-end instrumentation might not yet be as plug-and-play as back-end tracing. These are the *last-mile* gaps that the community is actively working on. The good news is that the trajectory is positive, every quarter, more components reach stability. However, as of 2025, you should go in with eyes open, knowing that a few rough edges remain.

## Adopting OpenTelemetry in 2025: Tips for Success

Given the challenges, how should organisations **adopt OpenTelemetry** effectively in 2025? 

### Start Small and Iterate

The key is to **start small and iterate**. Rather than a big-bang rollout across your entire platform, pick one or two services to instrument first. Ideally, choose a non-critical or internal service to pilot OTel – this allows your team to learn the ropes without impacting a customer-facing system. When starting, focus on the **stable, proven signals** like tracing [and metrics] before wading into newer areas. 

Distributed tracing is usually the best first step; it’s been GA for a while and gives immediate visibility into how requests flow through your system. Instrumenting traces [via the language SDK or an auto-instrumentation agent] will help build confidence and demonstrate value quickly. You can then add metrics and logs to the mix, and later experiment with profiles or other advanced signals as needed.

Using OpenTelemetry’s **auto-instrumentation** options can significantly flatten the learning curve. For many popular languages and frameworks [Java, Python, .NET, Node, etc.], 
OpenTelemetry provides auto-instrumentation agents that require minimal or zero code changes. These agents can automatically 
capture incoming HTTP requests, database calls, framework-specific operations, and more. By deploying an auto-instrumentation agent, you gain instant telemetry that 
can be piped to a backend of your choice, a quick win to show stakeholders some results. It’s a great way to bootstrap your observability without spending weeks writing manual instrumentation. 
Of course, for critical business logic, 
you’ll eventually want to add custom spans or metrics, but auto-instrumentation covers a lot of ground out of the box.

### Deploy Collector Early

Another tip is to **deploy the Collector early** and use it as your telemetry hub. Even if you start by pushing data to a simple backend [like logging to console or a local Jaeger instance], using a Collector gives you flexibility. You can add processors [for example, to redact sensitive data or sample high-volume traces] and easily switch or duplicate exports to different backends. It’s easier to tweak one Collector config than to redeploy multiple services with new exporter settings. The Collector’s stability in 2025 means you can rely on it as the backbone of your observability pipeline.

### Leverage Community Resources

Lastly, **leverage community resources**. The OpenTelemetry community is large and very active - there are public Slack channels, discussion forums, and weekly SIG [Special Interest Group] meetings for various languages and components. 
If you encounter a tricky issue while instrumenting something, someone on Slack or GitHub has experienced it before. The project’s maintainers and users often help newcomers navigate problems [though remember they are mostly volunteers!]. 
Also, keep an eye on official guides and example apps. The OpenTelemetry documentation site features a **demo application** that showcases a microservices architecture instrumented with OpenTelemetry, serving as a reference implementation. By adopting incrementally, using available tools, and learning from the community, you can mitigate the pain points and **avoid feeling overwhelmed** by OTel’s scope.

## Final Words..

For anyone still undecided, 2025 is an ideal time to evaluate OpenTelemetry. The project has matured significantly, featuring stable core signals, a maturing collector, and exciting new capabilities, such as profiling and AI instrumentation. At the same time, 
you should be aware of the challenges and plan for a measured adoption. The good news is that you don’t have to boil the 
ocean on day one; start with the basics [you’ll likely see benefits immediately when that first distributed trace lights up your dashboard] and grow from there. Given its trajectory, OpenTelemetry isn’t a passing trend, it’s rapidly
becoming **the undisputed standard** for observability data in our industry. Embracing it now will position you well for 
the future of monitoring and performance engineering. In the end, the effort invested in OpenTelemetry pays off by making your systems easier to understand, troubleshoot, and optimise and that is *well* worth it for any organisation aiming for reliability in an increasingly complex world.